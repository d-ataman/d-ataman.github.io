---
permalink: /
title: "Duygu Ataman, Ph.D."
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a post-doctoral at the University of ZÃ¼rich, at the Institute of Computational Linguistics. I am also a lecturer at the bachelor's studies in Computational Linguistics and Language Technology. I work on developing novel machine learning methods for natural language processing, specifically to generative tasks such as machine translation, text summarization as well as automatic linguistic analysis tools including morphological analysis and Part-of-Speech tagging under low-resource settings. I also take part in initiatives to develop corpora in low-resource languages and dialects.

Research
------
The main goal in my research is to improve the applicability of language technology in low-resource languages and tasks. Language technology is a highly promising tool with the potential of transforming how we use and benefit from education, media and business, although the state-of-the-art approaches are still not competitive enough to be deployed in a large part of the world. From a socioeconomic perspective, this includes languages spoken in geographically under-developed parts with few to none online written or spoken resources to build natural language processing systems. Linguistically these languages mostly intersect with morphologically-rich languages (language families spoken in Northern and Eastern Africa, Central and Northeastern Asia, South India, and many indigeneous American or Australian languages), which also have the data sparsity problem, where any collection of data is statistically insufficient to observe all possible surface forms of words in varying context, due to the exponentially growing nature of word structure. On the other hand, from the perspective of artifical intelligence and engineering, this problem is equivalent to learning to generalize from little to no data and using models with minimal capacity. I find this hardly challenging design problem quite interesting due to its potential in benefiting a tremendous amount of future applications, and at the same time, due to my background in electrical engineering where I had specifically gained expertise on developing opmitized software solutions for real-time computation-intensive multimedia technology, such as computer vision, signal processing or secure signal transmission.

In the context of natural language processing, currently the most promising approach to improve the performance in low-resource languages and tasks are multi-lingual and multi-task learning methods. This is why I joined the MUTAMUR project of Prof. Dr. Rico Sennrich which aims to investigate methods for knowledge sharing and transfer between machine learning models in natural language processing. The main focus of my current research is to investigate these methods under different settings and apply them in designing novel solutions to improve the generalization capability and accuracy of models under low-resource settings. In order to accelerate research in this field I recently initiated the organization of first workshop on Multilingual Representation Learning, which will take place in EMNLP 2021. The workshop aims to bring together researchers working on multi-lingual models and language adaptation around the world and aid to gain better understanding and interpretation of them so that they can be deployed in the most efficient way in various languages and tasks.

I am also interested in Bayesian approaches which are especially useful in applications which require unsupervised or semi-supervised learning under low-resource settings, so in a parallel line of work I study novel methods for designing latent-variable or geometric models that can help induce linguistic biases into the statistical model. In my Ph.D. which I completed in 2019 at the University of Trento, I studied morphology in all means from the aspects of linguistics, cognitive science and statistics, and designed a purely statistical formulation of it within the Bayesian framework, which could be implemented in generative models through variational eutoencoders to help generate better sentences in morphologically-rich and low-resource languages. This project was also carried out during my research visit at the School of Informatics at the University of Edinburgh. Since I finished my Ph.D. I have started studying syntax in order to design a more linguistically expressive statistical model of morphosyntax, which I hope will help better generalization in multi-lingual models.










